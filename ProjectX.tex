\documentclass{article}
\usepackage{amsmath,amsfonts}
\usepackage{hyperref}
\usepackage[autostyle]{csquotes}  
\title{Project X.0}
\author{Thomas Hofmann}
\begin{document}
\maketitle

\subsection*{Vision and Mission}

Project X aims at using  AI to create more humane compute experiences through novel devices, which require less effort and which are less detrimental to physical and mental health. Concretly, starting at the physical level, the use of static keyboards and screens, in particular with small scale factors, should be substituted by voice and gestures as natural modes of interaction. Moreover, on a cognitive level, transparency and ease of use should replace technological intricateness, while user-specific prediction and anticipation should help avoid uncessary verbosity and repetitiveness. Ultimately, human-machine interaction should be goverend by conversational principles and founded on the human interaction engine \cite{levinson2006human}. This requires the multifaceted use of machine learning techniques for voice recognition, visual perception, language understanding, and interaction policies. 

Naturally, such devices -- whether wearable or embedded -- will gather and process large amounts of privacy-sensitive data, in particular if they  are not explicitly activated by users, but are expected to provide some ongoing ambient background intelligence. This raises massive trust issues that can be best addressed by performing all the necessary computations on private devices. Associating control of data and its processing with physical devices will re-establish trustworthiness that has been lost with internet and cloud-based services. However, on the technological side, abandoning cloud computing principles creates challenges due to limited compute power as well as the inability to integrate data at  the population level.

\subsection*{Sketching a Home Device Scenario}

Standard screens are replaced by more dynamic and flexible projection mechanisms that may provide lower resolution and a less controlled visual output (e.g.~dependent on surface properties, interferring light sources, projection and viewing angles, etc.), but that can blend naturally into the home environment. This gives larger freedom of movement and flexibility to its use(ers). In order to optimize the display of information, the current location, pose, gaze and identity of the user need to be determined (on a continuous basis). Let us sketch a scenario that interactively guides users through a world of evolving news stories and podcasts. Here stories or document snippets can either be displayed to users or read to them (or, actually both). This requires voice synthesis (to read out) and possibly simple hand gestures for local navigation (skip, repeat/back, pause). Moreover it should be easy to move between modalitites -- e.g.~start  reading an article and then move over to (audio) listening. It may also be useful to offer skimming and summarization features. The system will keep track and memory of 

\newpage


as well as the attention state 



\newpage


that make unhealty technology. On the surface level, this includes keyboards, touchpads and screens. Naturally, this would make \ In addition, one can make use of visual recognition, i.e.~face detection, gaze tracking, gesture and finger tracking.

\newpage

\paragraph{Device} ... to be put on table/desk or on the floor. Microphone, ideally 

\bibliographystyle{acm}
\bibliography{projectx}
\end{document} 